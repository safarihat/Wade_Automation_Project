[program:celery_worker]
; Command to start the celery worker.
; Replace '/path/to/your/project' with the actual path to your project's root directory.
command=python run_celery.py
directory=C:/Users/safar/wade_automation_project_new

; User and group to run as.
; On Windows, you might not need these. On Linux, you might use 'user=www-data'.
; user=your_user
; group=your_group

; Number of processes to start. 
; You can increase this to scale up on a single machine.
numprocs=1

; Start the worker automatically when supervisord starts.
autostart=true

; Restart the worker automatically if it exits unexpectedly.
autorestart=true

; Where to write stdout logs.
stdout_logfile=C:/Users/safar/wade_automation_project_new/logs/celery_worker.log

; Where to write stderr logs.
stderr_logfile=C:/Users/safar/wade_automation_project_new/logs/celery_error.log

; Ensure the log directory exists.
; You will need to create the 'logs' directory in your project's root.

; --- Cloud Scalability Notes ---
; To scale horizontally, you would typically run this same supervisor configuration
; on multiple servers, all pointing to the same distributed message broker (like RabbitMQ or Redis).
; You could also use auto-scaling groups in the cloud to automatically add or remove
; servers running this worker based on CPU usage or queue length.
